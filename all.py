# -*- coding: utf-8 -*-
"""imbalance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BCiBrKOkzLnXtG2S0k-_GBoPxMlPCJ9E
"""

# ドライブのマウント
from google.colab import drive
drive.mount('/content/drive')

!unzip "drive/MyDrive/Colab Notebooks/DLBasics2024_colab/final/data/train.zip"

!unzip "drive/MyDrive/Colab Notebooks/DLBasics2024_colab/final/data/valid.zip"

!pip install transformers

import re
import random
import time
from statistics import mode
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
import torch
import torch.nn as nn
import torchvision
from torchvision import transforms, models
from transformers import AlbertTokenizer, AlbertModel
from torch.cuda.amp import autocast, GradScaler

!pip list | grep torch

torch.cuda.empty_cache()

def show_data(epochs, train_loss, train_acc, train_simple_acc, val_loss, val_acc, val_simple_acc): # 可視化用の関数
    plt.figure(figsize=(18, 8))

    plt.subplot(2, 3, 1)
    plt.plot(epochs, train_loss, label='Train Loss')
    plt.plot(epochs, val_loss, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Train and Validation Loss')
    plt.grid()
    plt.legend()

    plt.subplot(2, 3, 2)
    plt.plot(epochs, train_acc, label='Train Accuracy')
    plt.plot(epochs, val_acc, label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Train and Validation Accuracy')
    plt.grid()
    plt.legend()

    plt.subplot(2, 3, 3)
    plt.plot(epochs, train_simple_acc, label='Train Simple Accuracy')
    plt.plot(epochs, val_simple_acc, label='Validation Simple Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Simple Accuracy')
    plt.title('Train and Validation Simple Accuracy')
    plt.grid()
    plt.legend()

    plt.tight_layout()
    plt.show()

def set_seed(seed): # シード値を固定する関数
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def process_text(text): # テキストの前処理
    text = text.lower()
    num_word_to_digit = {
        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',
        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',
        'ten': '10'
    }
    for word, digit in num_word_to_digit.items():
        text = text.replace(word, digit)
    text = re.sub(r'(?<!\d)\.(?!\d)', '', text)
    text = re.sub(r'\b(a|an|the)\b', '', text)
    contractions = {
        "dont": "don't", "isnt": "isn't", "arent": "aren't", "wont": "won't",
        "cant": "can't", "wouldnt": "wouldn't", "couldnt": "couldn't"
    }
    for contraction, correct in contractions.items():
        text = text.replace(contraction, correct)
    text = re.sub(r"[^\w\s':]", ' ', text)
    text = re.sub(r'\s+,', ',', text)
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# 1. データローダーの作成
class VQADataset(torch.utils.data.Dataset):
    def __init__(self, df, image_dir, answer2idx, idx2answer, transform=None, answer=True):
        self.df = df
        self.image_dir = image_dir
        self.answer2idx = answer2idx
        self.idx2answer = idx2answer
        self.transform = transform
        self.answer = answer
        self.tokenizer = AlbertTokenizer.from_pretrained("albert-base-v2")

    def __getitem__(self, idx):
        # 画像の前処理
        image = Image.open(f"{self.image_dir}/{self.df['image'][idx]}")
        image = self.transform(image)
        # テキストの前処理
        question = self.df["question"][idx]
        question = process_text(question)
        encoding = self.tokenizer(question, return_tensors='pt', padding='max_length', truncation=True, max_length=32)
        input_ids = encoding['input_ids'].squeeze()
        attention_mask = encoding['attention_mask'].squeeze()
        token_type_ids = encoding['token_type_ids'].squeeze()

        if self.answer:
            answers = [self.answer2idx[process_text(answer["answer"])] for answer in self.df["answers"][idx]]
            mode_answer_idx = mode(answers)
            return image, input_ids, attention_mask, token_type_ids, torch.Tensor(answers), int(mode_answer_idx)
        else:
            return image, input_ids, attention_mask, token_type_ids

    def __len__(self):
        return len(self.df)

# 2. 評価指標の実装
def VQA_criterion(batch_pred: torch.Tensor, batch_answers: torch.Tensor):
    total_acc = 0.
    for pred, answers in zip(batch_pred, batch_answers):
        acc = 0.
        for i in range(len(answers)):
            num_match = 0
            for j in range(len(answers)):
                if i == j:
                    continue
                if pred == answers[j]:
                    num_match += 1
            acc += min(num_match / 3, 1)
        total_acc += acc / 10
    return total_acc / len(batch_pred)

# 3. モデルの実装
class VQAModel(nn.Module):
    def __init__(self, n_answer: int):
        super().__init__()
        self.efficientnet = models.efficientnet_b0(pretrained=True)
        self.bert = AlbertModel.from_pretrained("albert-base-v2")
        self.fc = nn.Sequential(
            nn.Linear(2048, 2048),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.25),
            nn.Linear(2048, n_answer)
        )

    def forward(self, image, input_ids, attention_mask, token_type_ids):
        image_feature = self.efficientnet.features(image)
        image_feature = torch.mean(image_feature, dim=[2, 3])
        text_feature = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
        text_feature = text_feature.pooler_output
        x = torch.cat([image_feature, text_feature], dim=1)
        x = self.fc(x)
        return x

# 4. 学習と評価の実装
def train(model, dataloader, optimizer, criterion, device):
    model.train()
    start = time.time()
    scaler = GradScaler()
    for image, input_ids, attention_mask, token_type_ids, answers, mode_answer in dataloader:
        image, input_ids, attention_mask, token_type_ids, answers, mode_answer = \
            image.to(device), input_ids.to(device), attention_mask.to(device), token_type_ids.to(device), answers.to(device), mode_answer.to(device)
        with autocast():
            pred = model(image, input_ids, attention_mask, token_type_ids)
            loss = criterion(pred, mode_answer.squeeze())
        optimizer.zero_grad()
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

    return time.time() - start

class gcn():
    def __init__(self):
        pass

    def __call__(self, x):
        mean = torch.mean(x)
        std = torch.std(x)
        return (x - mean)/(std + 10**(-6))

def main():
    set_seed(42)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(device)
    # データ拡張
    GCN = gcn()
    transform_train = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        GCN
    ])
    transform_test = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        GCN
    ])
    # データフレーム
    df_train = pd.read_json("drive/MyDrive/Colab Notebooks/DLBasics2024_colab/final/data/train.json")
    df_test = pd.read_json("drive/MyDrive/Colab Notebooks/DLBasics2024_colab/final/data/valid.json") # テストデータ
    # answer2idxの作成
    answer2idx = {}
    idx2answer = {}
    for answers in df_train["answers"]:
        for answer in answers:
            word = process_text(answer["answer"])
            if word not in answer2idx:
                answer2idx[word] = len(answer2idx)
    idx2answer = {v: k for k, v in answer2idx.items()}

    df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)
    # データセットの作成
    train_dataset = VQADataset(df=df_train, image_dir="train", answer2idx=answer2idx, idx2answer=idx2answer, transform=transform_train)
    test_dataset = VQADataset(df=df_test, image_dir="valid", answer2idx=answer2idx, idx2answer=idx2answer, transform=transform_test, answer=False)
    # データローダーの作成
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)
    # モデル構築
    model = VQAModel(n_answer=len(answer2idx)).to(device)
    num_epoch = 20
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)
    # 学習と評価
    for epoch in range(num_epoch):
        train_time = train(model, train_loader, optimizer, criterion, device) # 学習
        print(f"【{epoch + 1}/{num_epoch}】\n"
            f"train time: {train_time:.2f} [s]\n")
        # 提出用ファイルの作成
        if epoch+1==20:
            model.eval()
            submission = [] # 予測値
            submission_prob = [] # 確率値
            for image, input_ids, attention_mask, token_type_ids in test_loader:
                image, input_ids, attention_mask, token_type_ids = image.to(device), input_ids.to(device), attention_mask.to(device), token_type_ids.to(device)
                pred = model(image, input_ids, attention_mask, token_type_ids) # 予測
                pred_prob = list(pred.cpu().detach().numpy()) # 確率値のまま
                pred = pred.argmax(1).cpu().item() # 予測値
                submission.append(pred)
                submission_prob.append(pred_prob)
            # 予測値ファイルの作成
            submission = [train_dataset.idx2answer[id] for id in submission]
            submission = np.array(submission)
            np.save("drive/MyDrive/Colab Notebooks/DLBasics2024_colab/final/ensemble/pred_submission_"+str(epoch+1)+"epochs_3.npy", submission)
            # 確率値ファイルの作成
            submission_prob = np.array(submission_prob)
            np.save("drive/MyDrive/Colab Notebooks/DLBasics2024_colab/final/ensemble/prob_submission_"+str(epoch+1)+"epochs_3.npy", submission_prob)

if __name__ == "__main__":
    main()